#!/usr/bin/env python3
"""
Phase 0: Data Quality Validation
Run this BEFORE any analysis to ensure data meets quality standards
"""

import sys
from pathlib import Path
sys.path.insert(0, str(Path(__file__).parent.parent))

import pandas as pd
import logging
from ml.statistical_validator import DataQualityValidator, StatisticalValidator

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


def main():
    print("=" * 80)
    print("PHASE 0: DATA QUALITY VALIDATION")
    print("=" * 80)

    # Load training data
    print("\n1Ô∏è‚É£ Loading training data...")
    df = pd.read_parquet('data/ml_training/raw/training_data_complete.parquet')
    print(f"‚úÖ Loaded {len(df):,} samples")
    print(f"   Date range: {df['entry_date'].min()} to {df['entry_date'].max()}")
    print(f"   Unique stocks: {df['Ticker'].nunique()}")

    # Initialize validator
    validator = DataQualityValidator()
    stat_validator = StatisticalValidator()

    # Run comprehensive validation
    print("\n2Ô∏è‚É£ Running data quality checks...")
    validation_results = validator.validate_dataset(df)

    # Display results
    print("\n" + "=" * 80)
    print("DATA QUALITY REPORT")
    print("=" * 80)

    # Missing values
    print("\nüìä Missing Values:")
    missing = validation_results['missing_values']
    total_missing = sum(missing.values())
    if total_missing > 0:
        for col, count in missing.items():
            if count > 0:
                pct = count / len(df) * 100
                print(f"   {col}: {count:,} ({pct:.2f}%)")
    else:
        print("   ‚úÖ No missing values found")

    # Infinite values
    print("\nüìä Infinite Values:")
    infinite = validation_results['infinite_values']
    total_infinite = sum(infinite.values())
    if total_infinite > 0:
        for col, count in infinite.items():
            if count > 0:
                print(f"   ‚ö†Ô∏è {col}: {count:,}")
    else:
        print("   ‚úÖ No infinite values found")

    # Duplicates
    duplicates = validation_results['duplicate_rows']
    print(f"\nüìä Duplicate Rows: {duplicates:,}")
    if duplicates > 0:
        print("   ‚ö†Ô∏è Duplicate rows found - may indicate data collection issues")

    # Outliers in returns
    return_cols = [col for col in df.columns if col.startswith('return_')]
    if return_cols:
        print("\nüìä Return Outliers:")
        outlier_issues = 0
        for col in return_cols:
            if col in df.columns:
                outlier_key = f'outliers_{col}'
                if outlier_key in validation_results:
                    outlier_info = validation_results[outlier_key]
                    status = "‚úÖ" if outlier_info['is_acceptable'] else "‚ö†Ô∏è"
                    print(f"   {status} {col}: {outlier_info['n_outliers']:,} ({outlier_info['outlier_pct']:.2f}%)")
                    if not outlier_info['is_acceptable']:
                        outlier_issues += 1

        if outlier_issues > 0:
            print("   ‚ö†Ô∏è Excessive outliers detected - may indicate data quality issues")
    else:
        print("\nüìä Return Outliers: No return columns found")

    # Data gaps
    if 'data_gaps' in validation_results:
        gap_info = validation_results['data_gaps']
        print(f"\nüìä Data Completeness:")
        print(f"   Missing dates: {gap_info['n_missing_dates']:,}")
        print(f"   Completeness: {gap_info['data_completeness_pct']:.1f}%")
        if gap_info['n_missing_dates'] > 0:
            print("   ‚ö†Ô∏è Missing trading dates - may indicate gaps in data collection")
    else:
        print("\nüìä Data Completeness: No date column found")

    # Survivorship bias
    if 'survivorship' in validation_results:
        surv_info = validation_results['survivorship']
        print(f"\nüìä Survivorship Bias Check:")
        print(f"   Total stocks: {surv_info['total_stocks']}")
        print(f"   With recent data: {surv_info['stocks_with_recent_data']}")
        if surv_info['potentially_delisted']:
            print(f"   ‚ö†Ô∏è Potentially delisted: {len(surv_info['potentially_delisted'])}")
            print(f"   {surv_info['potentially_delisted'][:5]}")  # Show first 5
            print("   ‚ö†Ô∏è Survivorship bias risk - delisted stocks may be missing")
        else:
            print("   ‚úÖ No survivorship bias detected")

    # Overall assessment
    print("\n" + "=" * 80)
    overall = validation_results['overall_quality']
    print(f"üìä OVERALL QUALITY SCORE: {overall['quality_score']}/100")

    if overall['is_acceptable']:
        print("‚úÖ Data quality is acceptable - proceed to Phase 1")
    else:
        print("‚ö†Ô∏è Data quality issues found:")
        for issue in overall['issues_found']:
            print(f"   - {issue}")
        print("\n‚ùå Fix data quality issues before proceeding to analysis")
        return False

    # Calculate minimum sample size requirements
    print("\n" + "=" * 80)
    print("STATISTICAL REQUIREMENTS")
    print("=" * 80)

    min_samples = stat_validator.calculate_minimum_sample_size(target_ic=0.08)
    print(f"\nüìä Minimum Sample Size:")
    print(f"   Required: {min_samples:,} samples (for IC=0.08, power=0.80)")
    print(f"   Available: {len(df):,} samples")

    if len(df) >= min_samples:
        print(f"   ‚úÖ Sufficient data (excess: {len(df) - min_samples:,} samples)")
    else:
        print(f"   ‚ö†Ô∏è Insufficient data (shortfall: {min_samples - len(df):,} samples)")
        print("   ‚ö†Ô∏è Consider collecting more data or reducing target IC")

    # Save validation report
    print("\n3Ô∏è‚É£ Saving validation report...")
    report_path = 'data/ml_training/analysis/data_quality_report.txt'
    with open(report_path, 'w') as f:
        f.write("DATA QUALITY VALIDATION REPORT\n")
        f.write("=" * 80 + "\n\n")
        f.write(f"Date: {pd.Timestamp.now()}\n")
        f.write(f"Dataset: {len(df):,} samples\n")
        f.write(f"Quality Score: {overall['quality_score']}/100\n")
        f.write(f"Status: {'PASS' if overall['is_acceptable'] else 'FAIL'}\n")
        f.write("\n" + str(validation_results))

    print(f"‚úÖ Report saved to: {report_path}")

    return overall['is_acceptable']


if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)
